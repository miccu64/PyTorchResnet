{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class CIFAR10Dataset(Dataset):\n",
    "    def __init__(self, is_train: bool):\n",
    "        all_transforms = [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "        if is_train:\n",
    "            all_transforms = [transforms.RandomHorizontalFlip(), transforms.RandomCrop(32, padding=4)] + all_transforms\n",
    "\n",
    "        dataset = CIFAR10(root=\"data\", download=True, train=is_train, transform=transforms.Compose(all_transforms))\n",
    "        dataset.data = dataset.data[:2222]\n",
    "        dataset.targets = dataset.targets[:2222]\n",
    "\n",
    "        dataloader = DataLoader(dataset)\n",
    "\n",
    "        self.data = torch.cat([X for X, _ in dataloader])\n",
    "        self.labels = torch.eye(10)[torch.cat([y for _, y in dataloader])]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "train_dataset = CIFAR10Dataset(True)\n",
    "test_dataset = CIFAR10Dataset(False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset)\n",
    "test_dataloader = DataLoader(test_dataset)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class ResNetConvSizes:\n",
    "    def __init__(self, resnet_layers: int, block_size: int, conv2: int, conv3: int, conv4: int, conv5) -> None:\n",
    "        if block_size != 2 and block_size != 3:\n",
    "            raise ValueError(f\"Possible block sizes are [2, 3]. Provided: {block_size}\")\n",
    "        if resnet_layers < 5:\n",
    "            raise ValueError(f\"Possible lowest layers number: 5. Provided: {resnet_layers}\")\n",
    "        if any(value < 1 for value in (conv2, conv3, conv4)) or conv5 < 0:\n",
    "            raise ValueError(\"Wrong layers count\")\n",
    "\n",
    "        self.resnet_layers = resnet_layers\n",
    "        self.block_size = block_size\n",
    "        self.conv2 = conv2\n",
    "        self.conv3 = conv3\n",
    "        self.conv4 = conv4\n",
    "        self.conv5 = conv5\n",
    "\n",
    "        size = self.layers_count()\n",
    "        if size != resnet_layers:\n",
    "            raise ValueError(f\"Wrong summary ResNet size. Current: {size}, expected: {resnet_layers}\")\n",
    "\n",
    "    def layers_count(self) -> int:\n",
    "        return ((self.conv2 + self.conv3 + self.conv4 + self.conv5) * self.block_size) + 2\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"ConvSize(resnet_layers={self.resnet_layers}, block_size={self.block_size}, conv2={self.conv2}, conv3={self.conv3}, conv4={self.conv4}, conv5={self.conv5})\"\n",
    "    \n",
    "\n",
    "class ShortcutTypeEnum(Enum):\n",
    "    Convolution = 1\n",
    "    Padding = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Sequential,\n",
    "    Conv2d,\n",
    "    ReLU,\n",
    "    ModuleList,\n",
    "    BatchNorm2d,\n",
    "    ReLU,\n",
    "    Linear,\n",
    "    Flatten,\n",
    "    AdaptiveAvgPool2d,\n",
    "    Softmax,\n",
    ")\n",
    "\n",
    "\n",
    "class PaddingLayer(Module):\n",
    "    def __init__(self, in_channels: int):\n",
    "        super(PaddingLayer, self).__init__()\n",
    "        self.pad = (0, 0, 0, 0, in_channels // 2, in_channels // 2)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return torch.nn.functional.pad(x[:, :, ::2, ::2], pad=self.pad, mode=\"constant\", value=0.0)\n",
    "\n",
    "\n",
    "class ResNetModule(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        conv_sizes: ResNetConvSizes,\n",
    "        shortcut_type: ShortcutTypeEnum = ShortcutTypeEnum.Convolution,\n",
    "        momentum: float = 0.9,\n",
    "    ):\n",
    "        super(ResNetModule, self).__init__()\n",
    "\n",
    "        if momentum <= 0 or momentum >= 1:\n",
    "            raise ValueError(f\"Momentum must be value between (0, 1). Provided: {momentum}\")\n",
    "\n",
    "        self.conv_sizes = conv_sizes\n",
    "        self.momentum = momentum\n",
    "        self.shortcut_type = shortcut_type\n",
    "\n",
    "        self.initial_channels = self.latest_channels = 16\n",
    "\n",
    "        self.conv1 = Sequential(\n",
    "            # bias is redundant when using batch normalization\n",
    "            Conv2d(3, self.latest_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            BatchNorm2d(self.latest_channels, momentum=self.momentum),\n",
    "            ReLU()\n",
    "            # no pooling there\n",
    "        ).apply(self.__init_weights)\n",
    "\n",
    "        self.conv2 = self.__create_blocks(conv_sizes.conv2)\n",
    "        self.conv3 = self.__create_blocks(conv_sizes.conv3)\n",
    "        self.conv4 = self.__create_blocks(conv_sizes.conv4)\n",
    "        self.conv5 = self.__create_blocks(conv_sizes.conv5)\n",
    "\n",
    "        self.shortcuts = self.__create_shortcuts()\n",
    "\n",
    "        self.output = Sequential(AdaptiveAvgPool2d((1, 1)), Flatten(), Linear(self.latest_channels, 10), Softmax(dim=1))\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        all_convs = [self.conv2, self.conv3, self.conv4]\n",
    "        if self.conv_sizes.conv5 > 0:\n",
    "            all_convs.append(self.conv5)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        for index, conv_blocks in enumerate(all_convs):\n",
    "            previous_x = self.shortcuts[index](x)\n",
    "            for block in conv_blocks:\n",
    "                x = block(x) + previous_x\n",
    "                previous_x = x.clone()\n",
    "\n",
    "        return self.output(x)\n",
    "\n",
    "    def __create_shortcuts(self) -> ModuleList:\n",
    "        in_channels = self.initial_channels\n",
    "        shortcuts = ModuleList()\n",
    "\n",
    "        iters = 4 if self.conv_sizes.conv5 > 0 else 3\n",
    "        for _ in range(iters):\n",
    "            match self.shortcut_type:\n",
    "                case ShortcutTypeEnum.Convolution:\n",
    "                    out_channels = in_channels * 2\n",
    "                    seq = Sequential(\n",
    "                        Conv2d(in_channels, out_channels, kernel_size=1, stride=2, bias=False),\n",
    "                        BatchNorm2d(out_channels, momentum=self.momentum),\n",
    "                    ).apply(self.__init_weights)\n",
    "                    shortcuts = shortcuts.append(seq)\n",
    "\n",
    "                case ShortcutTypeEnum.Padding:\n",
    "                    shortcuts = shortcuts.append(Sequential(PaddingLayer(in_channels)))\n",
    "\n",
    "                case _:\n",
    "                    raise ValueError(\"Not supported shortcut type\")\n",
    "\n",
    "            in_channels *= 2\n",
    "\n",
    "        return shortcuts\n",
    "\n",
    "    def __create_blocks(self, conv_size: int) -> ModuleList:\n",
    "        modules = ModuleList()\n",
    "        if conv_size == 0:\n",
    "            return modules\n",
    "\n",
    "        create_block = self.__create_basic_block if self.conv_sizes.block_size == 2 else self.__create_bottleneck_block\n",
    "\n",
    "        modules.append(create_block(self.latest_channels, True))\n",
    "        self.latest_channels *= 2\n",
    "\n",
    "        for _ in range(1, conv_size):\n",
    "            modules.append(create_block(self.latest_channels))\n",
    "\n",
    "        return modules.apply(self.__init_weights)\n",
    "\n",
    "    def __init_weights(self, module):\n",
    "        if isinstance(module, (Conv2d, Linear)):\n",
    "            torch.nn.init.kaiming_normal_(module.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "\n",
    "    def __create_basic_block(self, in_channels: int, downsample_dimensions: bool = False) -> Sequential:\n",
    "        if not self.__is_power_of_2(in_channels):\n",
    "            raise ValueError(\"Input channels number is not power of 2\")\n",
    "\n",
    "        first_stride = 1\n",
    "        out_channels = in_channels\n",
    "\n",
    "        if downsample_dimensions:\n",
    "            first_stride *= 2\n",
    "            out_channels *= 2\n",
    "\n",
    "        return Sequential(\n",
    "            Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=first_stride, bias=False),\n",
    "            BatchNorm2d(out_channels, momentum=self.momentum),\n",
    "            ReLU(),\n",
    "            Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            BatchNorm2d(out_channels, momentum=self.momentum),\n",
    "        )\n",
    "\n",
    "    def __create_bottleneck_block(self, in_channels: int, downsample_dimensions: bool = False) -> Sequential:\n",
    "        first_stride = 1\n",
    "        internal_channels = in_channels // 4\n",
    "        out_channels = in_channels\n",
    "\n",
    "        if downsample_dimensions:\n",
    "            first_stride *= 2\n",
    "            internal_channels *= 2\n",
    "            out_channels *= 2\n",
    "\n",
    "        if not all(self.__is_power_of_2(num) for num in [in_channels, internal_channels, out_channels]):\n",
    "            raise ValueError(\"Channels number is not power of 2\")\n",
    "\n",
    "        return Sequential(\n",
    "            Conv2d(in_channels, internal_channels, padding=1, kernel_size=1, stride=first_stride, bias=False),\n",
    "            BatchNorm2d(internal_channels, momentum=self.momentum),\n",
    "            ReLU(),\n",
    "            Conv2d(internal_channels, internal_channels, padding=1, kernel_size=3, stride=1, bias=False),\n",
    "            BatchNorm2d(internal_channels, momentum=self.momentum),\n",
    "            ReLU(),\n",
    "            Conv2d(internal_channels, out_channels, padding=1, kernel_size=1, stride=1, bias=False),\n",
    "            BatchNorm2d(out_channels, momentum=self.momentum),\n",
    "        )\n",
    "\n",
    "    def __is_power_of_2(self, n: int) -> bool:\n",
    "        return (n & (n - 1) == 0) and n != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def find_optimal_parameters(conv_sizes: list[ResNetConvSizes]) -> dict:\n",
    "    net = NeuralNetRegressor(\n",
    "        module=ResNetModule, optimizer=torch.optim.SGD, criterion=torch.nn.MSELoss(), device=device, verbose=1\n",
    "    )\n",
    "    params = {\n",
    "        \"lr\": [0.1, 0.01],\n",
    "        \"max_epochs\": [2, 3],\n",
    "        \"batch_size\": [128, 256],\n",
    "        \"optimizer__weight_decay\": [10**-5, 10**-4, 10**-3],\n",
    "        \"module__conv_sizes\": conv_sizes,\n",
    "        \"module__shortcut_type\": [ShortcutTypeEnum.Convolution, ShortcutTypeEnum.Padding],\n",
    "        \"module__momentum\": [0.85, 0.9, 0.95],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(net, params, refit=False, verbose=1, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "\n",
    "    samples = 400\n",
    "    grid_search.fit(train_dataset.data[:samples], train_dataset.labels[:samples])\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    best_mse = -grid_search.best_score_\n",
    "    print(\"Best Mean Squared Error:\", best_mse)\n",
    "    print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "    return best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_sizes = [ResNetConvSizes(18, 2, 2, 4, 2, 0), ResNetConvSizes(18, 2, 2, 2, 2, 2)]\n",
    "resnet18_best_params = find_optimal_parameters(conv_sizes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
